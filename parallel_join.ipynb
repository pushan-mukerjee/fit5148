{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5148 - Distributed Databases and Big Data\n",
    "\n",
    "# Activity: Parallel Join#\n",
    "\n",
    "In this activity, we will learn and build different parallel algorithms for join queries. This practice will help you understand how parallel processing of a join operation can significantly improve the serial join operation which is considered to be one of the most expensive operations in relational database processing.\n",
    "\n",
    "**Instructions:**\n",
    "- You will be using Python 3.\n",
    "- Read the code base and comments carefully\n",
    "- After understanding the provided function, run the cell right below it to check if the result is correct.\n",
    "- Read carefully all the **Exercise** tasks below in each subheading. There are some code blocks that **you need to complete** yourself.\n",
    "\n",
    "**After this assignment you will:**\n",
    "- Be able to build serial join algorithms\n",
    "- Be able to build parallel join algorithms\n",
    "- Be able to compare the performance of the serial and parallel join algorithms\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "**What you need to remember**:\n",
    "- Run your cells using SHIFT+ENTER (or \"Run cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset ###\n",
    "In this activity, we use the following two tables R and S to explain and practice different parallel join algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R consists of 15 pairs, each comprising two attributes (nominal and numeric)\n",
    "R = [('Adele',8),('Bob',22),('Clement',16),('Dave',23),('Ed',11),\n",
    "     ('Fung',25),('Goel',3),('Harry',17),('Irene',14),('Joanna',2),\n",
    "     ('Kelly',6),('Lim',20),('Meng',1),('Noor',5),('Omar',19)]\n",
    "\n",
    "# S consists of 8 pairs, each comprising two attributes (nominal and numeric)\n",
    "S = [('Arts',8),('Business',15),('CompSc',2),('Dance',12),('Engineering',7),\n",
    "     ('Finance',21),('Geology',10),('Health',11),('IT',18)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Serial Join Algorithms ##\n",
    "\n",
    "Let's first understand serial join algorithms - join algorithms implemented in nonparallel machines. Parallel join algorithms adopt a data partitioning parallelism approach, whereby parallelism is achieved through data partitioning. That is, a join operation implemented on each processor would employ a serial join algorithm. In Section 2, we will learn more about parallel join algorithms.\n",
    "\n",
    "In this activity, we will consider the following **three** serial join algorithms:\n",
    " * **Nested-loop join algorithm**,\n",
    " * **Sort-merge join algorithm**,\n",
    " * **Hash-based join algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Nested-Loop Join Algorithm ###\n",
    "Nested-loop join is the simplest form of join algorithm. For each record of the\n",
    "first table, it goes through all records of the second table. This is repeated for all records of the first table. It is called a nested loop because it consists of two levels of loops: **inner loop (looping for the second table) and outer loop (looping for the first table)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Undertand and run the nested-loop join algorithm using the **join attribute - the numeric attribute** in two tables R and S. Then, discuss the time complexity of this algorithm as well as its pros and cons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NL_join(T1, T2):\n",
    "    \"\"\"\n",
    "    Perform the nested-loop join algorithm.\n",
    "    The join attribute is the numeric attribute in the input tables T1 & T2\n",
    "\n",
    "    Arguments:\n",
    "    T1 & T2 -- Tables to be joined\n",
    "\n",
    "    Return:\n",
    "    result -- the joined table\n",
    "    \"\"\"\n",
    "    result = []\n",
    "\n",
    "    ### START CODE HERE ### \n",
    "    \n",
    "    # For each record of R\n",
    "    for tr1 in T1:\n",
    "        # For each record of S\n",
    "        for tr2 in T2:\n",
    "            #If matched Then            \n",
    "            if (tr1[1] == tr2[1]):\n",
    "                # Store the record into the result list\n",
    "                result.append({\", \".join([tr1[0], str(tr1[1]), tr2[0]])})\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Adele, 8, Arts'}, {'Ed, 11, Health'}, {'Joanna, 2, CompSc'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NL_join(R, S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table aligh='left'>\n",
    "    <tr>\n",
    "     <td>[{'Adele, 8, Arts'}, {'Ed, 11, Health'}, {'Joanna, 2, CompSc'}]</td> \n",
    "    </tr>\n",
    " \n",
    "</table>\n",
    "\n",
    "This is N * N efficient. Hence as both tables grow the performance of the join will degrade. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SM_join(T1, T2):\n",
    "    \"\"\"\n",
    "    Perform the sort-merge join algorithm.\n",
    "    The join attribute is the numeric attribute in the input tables T1 & T2\n",
    "\n",
    "    Arguments:\n",
    "    T1 & T2 -- Tables to be joined\n",
    "\n",
    "    Return:\n",
    "    result -- the joined table\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    \n",
    "    # sort T1 based on the join attribute\n",
    "    s_T1 = list(T1)\n",
    "    s_T1 = sorted(s_T1, key=lambda s_T1: s_T1[1])\n",
    "    \n",
    "    # sort T2 based on the join attribute\n",
    "    s_T2 = list(T2)\n",
    "    s_T2 = sorted(s_T2, key=lambda s_T2: s_T2[1])\n",
    "   \n",
    "    ### START CODE HERE ### \n",
    "    i = j = 0\n",
    "    while True:\n",
    "        r = s_T1[i][1]\n",
    "        s = s_T2[j][1]\n",
    "        \n",
    "        # If join attribute s_T1(i) < join attribute s_T2(i)\n",
    "        if r < s:\n",
    "            i += 1\n",
    "        \n",
    "        # else \n",
    "        else:\n",
    "            # if join attribute s_T1(1) > join attribute s_T2(1)\n",
    "            if r > s:\n",
    "                j += 1   \n",
    "            # #---Implement here\n",
    "            \n",
    "            # else \n",
    "            else:\n",
    "                # put records s_T1(i) and s_T2(j) into the result and i++, j++\n",
    "                # #---Implement here\n",
    "                result.append({\", \".join([s_T1[i][0], str(s_T1[i][1]), s_T2[j][0]])})\n",
    "                #i += 1\n",
    "                j += 1\n",
    "                \n",
    "        # if either s_T1(i) or s_T2(j) is EOF Then break\n",
    "        if (i == len(s_T1)) or (j == len(s_T2)):\n",
    "                break\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2  Sort-Merge Join Algorithm ###\n",
    "Sort-merge join is based on sorting and merging operations. The first step of joining is to sort the two tables based on the joining attribute in an ascending order, and the second step is merging the two sorted tables.\n",
    "If the value of the joining attribute in R is smaller than that in S, it skips to the next value of the joining attribute in R.\n",
    "On the other hand, if the value of the joining attribute in R is greater than that in S, it skips to the next value of the joining attribute in S. When the two values match, the two corresponding records are concatenated and placed into the query result.\n",
    "\n",
    "**Exercise**: **Complete the sort-merge join algorithm** based on the above definition by implementing the following code block between '### START CODE HERE ###' and '### END CODE HERE ###'. Discuss the time complexity of this algorithm in terms if its efficiency. Also, compare it with the nest-loop join algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Joanna, 2, CompSc'}, {'Adele, 8, Arts'}, {'Ed, 11, Health'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a hash value\n",
    "SM_join(R, S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table aligh='left'>\n",
    "    <tr>\n",
    "     <td>[{'Joanna, 2, CompSc'}, {'Adele, 8, Arts'}, {'Ed, 11, Health'}]</td> \n",
    "    </tr>\n",
    " \n",
    "</table>\n",
    "\n",
    "N(1) + N(2) efficiency of the smallest table, so N times more efficient than Nested Loop join algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3  Hash-Based Join Algorithm ###\n",
    "A hash-based join is basically made up of two processes: `hashing` and `probing`. A hash table is created by hashing all records of the first table using a particular hash function. Records from the second table are also hashed with the same hash function and probed. If any match is found, the\n",
    "two records are concatenated and placed in the query result.\n",
    "\n",
    "A decision must be made about which table is to be hashed and which table is to be probed. Since a hash table has to be created, it would be better to choose the smaller table for hashing and the larger table for probing.\n",
    "\n",
    "**Exercise**: **Complete the hash-based join algorithm** by implementing the following code block between '### START CODE HERE ###' and '### END CODE HERE ###'. Discuss the time complexity of this algorithm in terms if its efficiency. Also, compare it with the above two join algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(r):\n",
    "    \"\"\"\n",
    "    We define a hash function 'H' that is used in the hashing process works \n",
    "    by summing the first and second digits of the hashed attribute, which\n",
    "    in this case is the join attribute. \n",
    "    \n",
    "    Arguments:\n",
    "    r -- a record where hashing will be applied on its join attribute\n",
    "\n",
    "    Return:\n",
    "    result -- the hash index of the record r\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert the value of the join attribute into the digits\n",
    "    digits = [int(d) for d in str(r[1])]\n",
    "    \n",
    "    # Calulate the sum of elemenets in the digits\n",
    "    return sum(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H(R[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table aligh='left'>\n",
    "    <tr>\n",
    "     <td>4</td> \n",
    "    </tr>\n",
    " \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HB_join(T1, T2):\n",
    "    \"\"\"\n",
    "    Perform the hash-based join algorithm.\n",
    "    The join attribute is the numeric attribute in the input tables T1 & T2\n",
    "\n",
    "    Arguments:\n",
    "    T1 & T2 -- Tables to be joined\n",
    "\n",
    "    Return:\n",
    "    result -- the joined table\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    dic = {} # We will use a dictionary\n",
    "    \n",
    "    # For each record in table T2\n",
    "    for s in T2:\n",
    "        # Hash the record based on join attribute value using hash function H into hash table\n",
    "        s_key = H(s)\n",
    "        if s_key in dic:\n",
    "            dic[s_key].add(s) # If there is an entry\n",
    "        else:\n",
    "            dic[s_key] = {s}\n",
    "            \n",
    "    # For each record in table T1 (probing)\n",
    "    for r in T1:\n",
    "        # Hash the record based on join attribute value using H\n",
    "        r_key = H(r)\n",
    "\n",
    "        # If an index entry is found Then (ie. Probe the dic)\n",
    "        if r_key in dic: \n",
    "        # #---Implement here: You need to \n",
    "            for s in dic[r_key]:\n",
    "                if s[1] == r[1]: # Compare each record on this index entry with the record of table T1\n",
    "                    result.append({\", \".join([r[0], str(r[1]), s[0]])}) # If the key is the same then put the result \n",
    "       ### END CODE HERE ###\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Adele, 8, Arts'}, {'Ed, 11, Health'}, {'Joanna, 2, CompSc'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the partitioned result\n",
    "HB_join(R,S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table aligh='left'>\n",
    "    <tr>\n",
    "     <td>[{'Adele, 8, Arts'}, {'Ed, 11, Health'}, {'Joanna, 2, CompSc'}]\n",
    "</td> \n",
    "    </tr>\n",
    " \n",
    "</table>\n",
    "\n",
    "Almost 2N Efficiency if the data is distributed between both tables fairly evenly with respect to key values. \n",
    "If the data distribution with respect to the key values is skewed, then the probing can be inefficient for the join keys with large number of values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2 Parallel Join Algorithms ##\n",
    "Parallelism of join queries is achieved through data parallelism, whereby the same task is applied to different parts of the data. That is, after data partitioning has been completed, each processor will have its own data to work with. Thus, each processor will apply **any serial join algorithm**. Once this is carried out in each processor, the final results of the join operation are consolidated from the results obtained from different processors. \n",
    "\n",
    "We now look into the following two parallel join algorithms:\n",
    " * **Divide and Broadcast-Based Parallel Join Algorithms**\n",
    " * **Disjoint Partitioning-Based Parallel Join Algorithms**\n",
    "\n",
    "\n",
    "### 2.1 Divide and Broadcast-Based Parallel Join Algorithms ###\n",
    "These algorithms consist of two stages: (1) data partitioning using the divide and broadcast method and (2) a local join. \n",
    "\n",
    "The divide and broadcast data partitioning method consists of dividing one table into multiple disjoint partitions, where each partition is allocated a processor, and broadcasts the other table to all available processors. Dividing one table may be done simply by using equal division, so that each partition will have the same size, whereas broadcasting is actually replicating the content of the second table to all processors. Thus it is preferable for the smaller table to be broadcast and the larger table to be divided.\n",
    "\n",
    "**Exercise**: Understand how a divide and broadcast-based parallel join algorithms works given the tables R and S above. We assume that **the  hash-based join algorithm (i.e. `HB_join(.)`)** are used (see the above) and **the round-robin data partitioning** function that designed for \"Parallel Search\" acitivity (i.e. see below: **`rr_partition(.)`**) is used to implement this parallel join algorithm. Also, we assume that we use a shared-memory architecture is used, so there is no replication of the broadcast table S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round-robin data partitionining function\n",
    "def rr_partition(data, n):\n",
    "    \"\"\"\n",
    "    Perform data partitioning on data\n",
    "\n",
    "    Arguments:\n",
    "    data -- an input dataset which is a list\n",
    "    n -- the number of processors\n",
    "\n",
    "    Return:\n",
    "    result -- the paritioned subsets of D\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        result.append([])\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    \n",
    "    # Calculate the number of the elements to be allocated to each bin\n",
    "    n_bin = len(data)/n\n",
    "    \n",
    "    # For each bin, perform the following\n",
    "    for index, element in enumerate(data): \n",
    "        # Calculate the index of the bin that the current data point will be assigned\n",
    "        index_bin = (int) (index % n)\n",
    "        #print(str(index) + \":\" + str(element))\n",
    "        result[index_bin].append(element)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include this package for parallel processing\n",
    "import multiprocessing as mp\n",
    "\n",
    "def DDP_join(T1, T2, n_processor):\n",
    "    \"\"\"\n",
    "    Perform a divide and broadcast-based parallel join algorithms.\n",
    "    The join attribute is the numeric attribute in the input tables T1 & T2\n",
    "\n",
    "    Arguments:\n",
    "    T1 & T2 -- Tables to be joined\n",
    "    n_processor -- the number of parallel processors\n",
    "\n",
    "    Return:\n",
    "    result -- the joined table\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    \n",
    "    # Partition T1 into sub-tables using rr_partition().\n",
    "    # The number of the sub-tables must be the equal to the n_processor\n",
    "    T1_subsets = rr_partition(T1, n_processor)\n",
    "    \n",
    "    # Pool: a Python method enabling parallel processing. \n",
    "    pool = mp.Pool(processes = n_processor)\n",
    "    \n",
    "    for t1 in T1_subsets:\n",
    "        # Apply a join on each processor\n",
    "        \n",
    "        # Note that as we assume a shared-memory architecture, no replication\n",
    "        # of the broadcast table (in this case: table T2 (smaller table) occurs.\n",
    "        result = pool.apply_async(HB_join, [t1, T2])\n",
    "        output = result.get()\n",
    "        results.append(output)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'Adele, 8, Arts'}, {'Joanna, 2, CompSc'}], [{'Ed, 11, Health'}], []]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_processor = 3\n",
    "DDP_join(R, S, n_processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table aligh='left'>\n",
    "    <tr>\n",
    "     <td>[[{'Adele, 8, Arts'}, {'Joanna, 2, CompSc'}], [{'Ed, 11, Health'}], []]\n",
    "</td> \n",
    "    </tr>\n",
    " \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Disjoint Partitioning-Based Parallel Join Algorithms ###\n",
    "These algorithms also consist of two stages: a data partitioning stage using a disjoint partitioning and a local join. For the data partitioning, a disjoint partitioning, such as range partitioning or hash partitioning, may be used.\n",
    "\n",
    "\n",
    "**Exercise**: Complete the following a disjoint partitioning-based parallel join algorithm. \n",
    "\n",
    "Use all the three serial join algorithms above, and see whether the joined results are the same or not:\n",
    " * **Nested-loop join algorithm**\n",
    " * **Sort-merge join algorithm**\n",
    " * **Hash-based join algorithm**\n",
    " \n",
    "As a data partitioning method, use the range partitioninig method that we provided for \"Parallel Search\" acitivity (i.e. **`range_partition(.)`**).\n",
    "Assume that we have **3 parallel processors**, processor 1 will get records with join attribute value between 1 and 9, processor 2 between 10 and 19, and processor 3 between 20 and 29. **Note that you need to modify this function in the way that it partitions the table on the join attribute**.\n",
    "\n",
    "Note that both tables R and S need to be partitioned based on the join attribute with the same range partitioning function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range data partitionining function (Need to modify as instructed above)\n",
    "def range_partition(data, range_indices):\n",
    "    \"\"\"\n",
    "    Perform range data partitioning on data based on the join attribute\n",
    "\n",
    "    Arguments:\n",
    "    data -- an input dataset which is a list\n",
    "    range_indices -- the index list of ranges to be split\n",
    "\n",
    "    Return:\n",
    "    result -- the paritioned subsets of D\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    ### START CODE HERE ###  \n",
    "    # First, we sort the dataset according their values  \n",
    "    new_data = list(data)\n",
    "    new_data = sorted(new_data, key=lambda new_data: new_data[1])\n",
    "    #new_data.sort() #--- This should be modified\n",
    "    \n",
    "    # Calculate the number of bins\n",
    "    n_bin = len(range_indices) \n",
    "\n",
    "    # For each bin, perform the following\n",
    "    for i in range(n_bin): \n",
    "        # Find elements to be belonging to each range\n",
    "        s = [x for x in new_data if x[1] < range_indices[i]] #--- This should be modified\n",
    "        # Add the partitioned list to the result\n",
    "        result.append(s) \n",
    "        # Find the last element in the previous partition\n",
    "        last_element = s[len(s)-1]\n",
    "        # Find the index of of the last element\n",
    "        last = new_data.index(last_element)\n",
    "        # Remove the partitioned list from the dataset\n",
    "        new_data = new_data[int(last)+1:] \n",
    "\n",
    "        # Append the last remaining data list\n",
    "    result.append([x for x in new_data if x[1] >= range_indices[n_bin-1]]) #--- This should be modified\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Meng', 1),\n",
       "  ('Joanna', 2),\n",
       "  ('Goel', 3),\n",
       "  ('Noor', 5),\n",
       "  ('Kelly', 6),\n",
       "  ('Adele', 8)],\n",
       " [('Ed', 11), ('Irene', 14), ('Clement', 16), ('Harry', 17), ('Omar', 19)],\n",
       " [('Lim', 20), ('Bob', 22), ('Dave', 23), ('Fung', 25)]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your range partition function\n",
    "range_partition(R, [10, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table aligh='left'>\n",
    "    <tr>\n",
    "     <td>[[('Meng', 1),('Joanna', 2),('Goel', 3),('Noor', 5),('Kelly', 6),('Adele', 8)],</td> \n",
    "    </tr>\n",
    " <tr>\n",
    "     <td> [('Ed', 11), ('Irene', 14), ('Clement', 16), ('Harry', 17), ('Omar', 19)],</td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "     <td>[('Lim', 20), ('Bob', 22), ('Dave', 23), ('Fung', 25)]]</td> \n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPBP using Hash-based join algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include this package for parallel processing\n",
    "import multiprocessing as mp\n",
    "\n",
    "def DPBP_join(T1, T2, n_processor):\n",
    "    \"\"\"\n",
    "    Perform a disjoint partitioning-based parallel join algorithm.\n",
    "    The join attribute is the numeric attribute in the input tables T1 & T2\n",
    "\n",
    "    Arguments:\n",
    "    T1 & T2 -- Tables to be joined\n",
    "    n_processor -- the number of parallel processors\n",
    "\n",
    "    Return:\n",
    "    result -- the joined table\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    \n",
    "    #--- Implement the algorithm\n",
    "    \n",
    "    # Partition T1 & T2 into sub-tables using range_partition().\n",
    "    T1_subsets = range_partition(T1, [10, 20]) \n",
    "    T2_subsets = range_partition(T2, [10, 20])\n",
    "    \n",
    "    # The number of the sub-tables must be the equal to the n_processor\n",
    "    \n",
    "    # Apply local join for each processor\n",
    "    # Pool: a Python method enabling parallel processing. \n",
    "    pool = mp.Pool(processes = n_processor)\n",
    "    processor = 0 #initialise processor number in order to loop through all processors \n",
    "    \n",
    "    for processor in range(n_processor-1): #for each processor\n",
    "\n",
    "        # Select the table partitions on the processor\n",
    "        t1 = T1_subsets[processor]\n",
    "        t2 = T2_subsets[processor]\n",
    " \n",
    "        # join the table partitions on the processor using a self-join algorithm\n",
    "        results = pool.apply_async(HB_join, [t1, t2])\n",
    "        output = results.get() #get join results for this processor\n",
    "        result.append(output) #add join result of this processor to the overall result\n",
    "        processor += 1 #next processor\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'Joanna, 2, CompSc'}, {'Adele, 8, Arts'}], [{'Ed, 11, Health'}]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_processor = 3\n",
    "DPBP_join(R, S, n_processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPBP using Sort-Merge join algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include this package for parallel processing\n",
    "import multiprocessing as mp\n",
    "\n",
    "def DPBP_join(T1, T2, n_processor):\n",
    "    \"\"\"\n",
    "    Perform a disjoint partitioning-based parallel join algorithm.\n",
    "    The join attribute is the numeric attribute in the input tables T1 & T2\n",
    "\n",
    "    Arguments:\n",
    "    T1 & T2 -- Tables to be joined\n",
    "    n_processor -- the number of parallel processors\n",
    "\n",
    "    Return:\n",
    "    result -- the joined table\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    \n",
    "    #--- Implement the algorithm\n",
    "    \n",
    "    # Partition T1 & T2 into sub-tables using range_partition().\n",
    "    T1_subsets = range_partition(T1, [10, 20]) \n",
    "    T2_subsets = range_partition(T2, [10, 20])\n",
    "    \n",
    "    # The number of the sub-tables must be the equal to the n_processor\n",
    "    \n",
    "    # Apply local join for each processor\n",
    "    # Pool: a Python method enabling parallel processing. \n",
    "    pool = mp.Pool(processes = n_processor)\n",
    "    processor = 0 #initialise processor number in order to loop through all processors \n",
    "    \n",
    "    for processor in range(n_processor-1): #for each processor\n",
    "\n",
    "        # Select the table partitions on the processor\n",
    "        t1 = T1_subsets[processor]\n",
    "        t2 = T2_subsets[processor]\n",
    " \n",
    "        # join the table partitions on the processor using a self-join algorithm\n",
    "        results = pool.apply_async(SM_join, [t1, t2])\n",
    "        output = results.get() #get join results for this processor\n",
    "        result.append(output) #add join result of this processor to the overall result\n",
    "        processor += 1 #next processor\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'Joanna, 2, CompSc'}, {'Adele, 8, Arts'}], [{'Ed, 11, Health'}]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_processor = 3\n",
    "DPBP_join(R, S, n_processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPBP using Nested Loop join algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include this package for parallel processing\n",
    "import multiprocessing as mp\n",
    "\n",
    "def DPBP_join(T1, T2, n_processor):\n",
    "    \"\"\"\n",
    "    Perform a disjoint partitioning-based parallel join algorithm.\n",
    "    The join attribute is the numeric attribute in the input tables T1 & T2\n",
    "\n",
    "    Arguments:\n",
    "    T1 & T2 -- Tables to be joined\n",
    "    n_processor -- the number of parallel processors\n",
    "\n",
    "    Return:\n",
    "    result -- the joined table\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    \n",
    "    #--- Implement the algorithm\n",
    "    \n",
    "    # Partition T1 & T2 into sub-tables using range_partition().\n",
    "    T1_subsets = range_partition(T1, [10, 20]) \n",
    "    T2_subsets = range_partition(T2, [10, 20])\n",
    "    \n",
    "    # The number of the sub-tables must be the equal to the n_processor\n",
    "    \n",
    "    # Apply local join for each processor\n",
    "    # Pool: a Python method enabling parallel processing. \n",
    "    pool = mp.Pool(processes = n_processor)\n",
    "    processor = 0 #initialise processor number in order to loop through all processors \n",
    "    \n",
    "    for processor in range(n_processor-1): #for each processor\n",
    "\n",
    "        # Select the table partitions on the processor\n",
    "        t1 = T1_subsets[processor]\n",
    "        t2 = T2_subsets[processor]\n",
    " \n",
    "        # join the table partitions on the processor using a self-join algorithm\n",
    "        results = pool.apply_async(NL_join, [t1, t2])\n",
    "        output = results.get() #get join results for this processor\n",
    "        result.append(output) #add join result of this processor to the overall result\n",
    "        processor += 1 #next processor\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'Joanna, 2, CompSc'}, {'Adele, 8, Arts'}], [{'Ed, 11, Health'}]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_processor = 3\n",
    "DPBP_join(R, S, n_processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table aligh='left'>\n",
    "    <tr>\n",
    "     <td>[[{'Joanna, 2, CompSc'}, {'Adele, 8, Arts'}], [{'Ed, 11, Health'}], []]\n",
    "\n",
    "</td> \n",
    "    </tr>\n",
    " \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on finishing this activity!\n",
    "\n",
    "<font color='blue'>\n",
    "**Wrap up what we've learned:**\n",
    "- The join operation is one of the most expensive operations in relational query processing, and hence the parallelizing join operation brings significant benefits. \n",
    "- Parallel join algorithms are generally formed in two stages: data partitioning and local join.\n",
    "- Data partitioning is performed by the two operations - divide and broadcast\n",
    "- We are now able to build different local join operations: nested-loop join, sort-merge join, and hash join. \n",
    "- We now now able to build different parallel join algorithms using different data partitioning algorithms and serial join operations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "from pyspark import SparkContext # spark\n",
    "from pyspark.streaming import StreamingContext # spark streaming\n",
    "import sys\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from pprint import pprint #for printing Mongodb output in the queries\n",
    "import json\n",
    "import datetime as dt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient () #defining the Mongodb client.\n",
    "result = client.drop_database('as2TaskB') #ensure that the as2TaskB database \n",
    "                                          #doesn't already exist\n",
    "\n",
    "db = client.as2TaskB #defining the db\n",
    "\n",
    "fireCollection = db.fire #define a new collection for fire data. \n",
    "                         #This will store fire data plus the \n",
    "                         #the embedded climate data associated \n",
    "                         #with each fire\n",
    "\n",
    "climateCollection = db.climate #define a new collection \n",
    "                               #for the climate data\n",
    "\n",
    "result = fireCollection.drop() #Ensure that the fire collection \n",
    "                               #does not already exist in Mongo db\n",
    "\n",
    "result = climateCollection.drop() #Ensure that the fire collection \n",
    "                                  #does not already exist in Mongo db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sendNewPartition(iter):\n",
    "    connection = MongoClient()\n",
    "    db = connection.get_database('as2TaskB')\n",
    "    climateCollection = db.climate\n",
    "    fireCollection = db.fire\n",
    "    \n",
    "    for record in iter:\n",
    "        #print(record)\n",
    "        datestamp = record[0]\n",
    "        #climateRec = record[1]\n",
    "        fireRec = record[1]\n",
    "        recType = fireRec[0]      \n",
    "        #recType = climateRec[0]\n",
    " \n",
    "        if recType == \"'cdata'\": \n",
    "            station = int(climateRec[1])\n",
    "            air_temp = int(climateRec[2])\n",
    "            rel_humidity = float(climateRec[3])\n",
    "            windspeed_knots = float(climateRec[4])\n",
    "            maxwind_speed = float(climateRec[5])\n",
    "            precipitation = climateRec[6]\n",
    "            climateDf = pd.DataFrame({'Date':str(dt.datetime.now().strftime(\"%Y-%m-%d\")), 'Station':station, 'Air_Temperature_Celcius':air_temp, 'Relative_Humidity':rel_humidity, 'WindSpeed_knots':windspeed_knots, 'Max_Wind_Speed':maxwind_speed, 'Precipitation ':precipitation}, index=[0])\n",
    "            climateRecord = json.loads(climateDf.to_json(orient='records')) \n",
    "            print(climateRecord)\n",
    "            climateCollection.insert_many(climateRecord)\n",
    "        if recType == \"'fdata'\": \n",
    "            latitude = float(fireRec[1])\n",
    "            longitude = float(fireRec[2])\n",
    "            surfacetemp_kelvin = float(fireRec[3])\n",
    "            power = float(fireRec[4])\n",
    "            confidence = int(fireRec[5])\n",
    "            surfacetemp_celcius = int(fireRec[6])\n",
    "            fireDf = pd.DataFrame({'Date':str(dt.datetime.now().strftime(\"%Y-%m-%d\")), 'Datetime':str(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")), 'Latitiude':latitude, 'Longitude':longitude, 'Surface_Temperature_Kelvin':surfacetemp_kelvin, 'Power':power, 'Confidence':confidence, 'Surface_Temperature_Celcius ':surfacetemp_celcius}, index=[0])\n",
    "            #fireDf[\"Climate\"] = climateRecord\n",
    "            fireRecord = json.loads(fireDf.to_json(orient='records'))\n",
    "            print(fireRecord)\n",
    "            fireCollection.insert_many(fireRecord)        \n",
    "    connection.close()   \n",
    "    \n",
    "#str(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "def sendPartition(iter):\n",
    "    connection = MongoClient()\n",
    "    db = connection.get_database('as2TaskB')\n",
    "    climateCollection = db.climate\n",
    "    fireCollection = db.fire\n",
    "    \n",
    "    for record in iter:\n",
    "        datestamp = record[0]\n",
    "        eventRec = record[1]\n",
    "        eventType = eventRec[0]      \n",
    " \n",
    "        if eventType == \"'cdata'\": \n",
    "            station = int(eventRec[1])\n",
    "            air_temp = int(eventRec[2])\n",
    "            rel_humidity = float(eventRec[3])\n",
    "            windspeed_knots = float(eventRec[4])\n",
    "            maxwind_speed = float(eventRec[5])\n",
    "            precipitation = eventRec[6]\n",
    "            climateDf = pd.DataFrame({'Date':str(dt.datetime.now().strftime(\"%Y-%m-%d\")), 'Station':station, 'Air_Temperature_Celcius':air_temp, 'Relative_Humidity':rel_humidity, 'WindSpeed_knots':windspeed_knots, 'Max_Wind_Speed':maxwind_speed, 'Precipitation ':precipitation}, index=[0])\n",
    "            climateRecord = json.loads(climateDf.to_json(orient='records')) \n",
    "            print(climateRecord)\n",
    "            climateCollection.insert_many(climateRecord)\n",
    "        if eventType == \"'fdata'\": \n",
    "            latitude = float(eventRec[1])\n",
    "            longitude = float(eventRec[2])\n",
    "            surfacetemp_kelvin = float(eventRec[3])\n",
    "            power = float(eventRec[4])\n",
    "            confidence = int(eventRec[5])\n",
    "            surfacetemp_celcius = int(eventRec[6])\n",
    "            fireDf = pd.DataFrame({'Date':str(dt.datetime.now().strftime(\"%Y-%m-%d\")), 'Datetime':str(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")), 'Latitiude':latitude, 'Longitude':longitude, 'Surface_Temperature_Kelvin':surfacetemp_kelvin, 'Power':power, 'Confidence':confidence, 'Surface_Temperature_Celcius ':surfacetemp_celcius}, index=[0])\n",
    "            #fireDf[\"Climate\"] = climateRecord\n",
    "            fireRecord = json.loads(fireDf.to_json(orient='records'))\n",
    "            print(fireRecord)\n",
    "            fireCollection.insert_many(fireRecord)        \n",
    "    connection.close()   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#S1 = ssc.socketTextStream(\"localhost\", 9999)\n",
    "#S2 = ssc.socketTextStream(\"localhost\", 8085)\n",
    "\n",
    "    # Create windowed stream\n",
    "#    wS1 = S1.window(10)\n",
    "#    wS2 = S2.window(1)\n",
    "\n",
    "#    wS1.flatMap(lambda line: line.split(\",\")).pprint()\n",
    "#    wS2.flatMap(lambda line: line.split(\",\")).pprint()\n",
    "\n",
    "    # Perform join\n",
    "#    joinedStream = wS1.join(wS2)\n",
    "\n",
    "#    joinedStream.foreachRDD(lambda rdd: rdd.foreach(lambda x: print(x)))\n",
    "\n",
    "\n",
    "#rdd = sc.parallelize([(\"red\",20),(\"red\",30),(\"blue\", 100)])\n",
    "#rdd2 = sc.parallelize([(\"red\",40),(\"red\",50),(\"yellow\", 10000)])\n",
    "#rdd.join(rdd2).collect()\n",
    "# Gives [('red', (20, 40)), ('red', (20, 50)), ('red', (30, 40)), ('red', (30, 50))]\n",
    "\n",
    "#(\"'2018-10-07 16:31:42'\", [\"'cdata'\", '948701', '9', '43.2', '4.9', '8.0', \"' 0.00I'\", \"'2018-10-07 16:31:42'\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes to examiner**\n",
    "\n",
    "Below is an example of streaming from one of the Ports (Climate Data), as listening to both streams on both ports simulataneously doesn't seem to streaming the data. \n",
    "\n",
    "To listen to FireData stream, the climateData stream can be commented out, and the FireData stream uncommented.\n",
    "\n",
    "Both the ClimateData and FireDatawork indepedently and write to MongoDb, however the joinedStream, required for the embedded data model in Task B, doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We add this line to avoid an error : \"Cannot run multiple SparkContexts at once\". If there is an existing spark context, we will reuse it instead of creating a new context.\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "# Create a local StreamingContext with as many working processors as possible and a batch interval of 10 seconds            \n",
    "batch_interval = 5\n",
    "\n",
    "# If there is no existing spark context, we now create a new context\n",
    "if (sc is None):\n",
    "    sc = SparkContext(master=\"local[3]\", appName = \"WordCountApp\")\n",
    "ssc = StreamingContext(sc, batch_interval)\n",
    "\n",
    "host = \"localhost\"\n",
    "port1 = \"8085\"\n",
    "port2 = \"9997\"\n",
    "\n",
    "climateStream = ssc.socketTextStream(host, int(port1))\n",
    "fireStream = ssc.socketTextStream(host, int(port2))\n",
    "\n",
    "#Create 5 second windows for each stream \n",
    "wclimateStream = climateStream.window(5)\n",
    "wfireStream = fireStream.window(5)\n",
    "\n",
    "#Map the windowed streams to (Datestamp, EventRecord) RDD's so they can be joined on datestamp.\n",
    "climateRecs = wclimateStream.map(lambda climateRec: climateRec[1:-1].split(\", \")).map(lambda climateRec: (climateRec[7][1:20], climateRec))\n",
    "fireRecs = wfireStream.map(lambda fireRec: fireRec[1:-1].split(\", \")).map(lambda fireRec: (fireRec[7][1:20], fireRec))\n",
    "\n",
    "#create a joined stream to create RDDs of the form (Datestamp, (climateRec, fireRec))\n",
    "joinedStream = climateRecs.join(fireRecs) #left outer join required as a climatic day may contain 0 or many fires.\n",
    "\n",
    "#Store the event RDDs in the MongoDB database using sendPartition procedure\n",
    "#climateRecs.foreachRDD(lambda rdd: rdd.foreachPartition(sendPartition))\n",
    "#fireRecs.foreachRDD(lambda rdd: rdd.foreachPartition(sendPartition))\n",
    "#joinedStream.foreachRDD(lambda rdd: rdd.foreachPartition(sendPartition))\n",
    "joinedStream.foreachRDD(lambda rdd: rdd.foreach(lambda x: print(x)))\n",
    "\n",
    "# Print the result                            \n",
    "#climateRecs.pprint()\n",
    "#fireRecs.pprint()\n",
    "joinedStream.pprint()\n",
    "\n",
    "#Start Streaming\n",
    "ssc.start()\n",
    "try:\n",
    "    ssc.awaitTermination(timeout=60)\n",
    "except KeyboardInterrupt:\n",
    "    ssc.stop()\n",
    "    sc.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()\n",
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

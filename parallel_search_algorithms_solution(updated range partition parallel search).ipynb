{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5148 - Distributed Databases and Big Data\n",
    "\n",
    "# Activity: Parallel Search#\n",
    "\n",
    "In this activity, we will learn and build different parallel search algorithms on various data partitioning strategies. This work will help you to better understand and familiarise you with how parallel search algorithms can work and be implemented.\n",
    "\n",
    "**Instructions:**\n",
    "- You will be using Python 3.\n",
    "- Read the code base and comments carefully\n",
    "- After understanding the provided function, run the cell right below it to check if the result is correct.\n",
    "- Read carefully all the **Exercise** tasks below in each subheading. There are some code blocks that **you need to complete** yourself.\n",
    "\n",
    "**After this assignment you will:**\n",
    "- Be able to use iPython Notebooks\n",
    "- Be able to build data partitionining strategies\n",
    "- Be able to build basic search algorithms\n",
    "- Be able to understand and build parallel search algorithms based on data partitioning techniques and basic search algorithms\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "**What you need to remember**:\n",
    "- Run your cells using SHIFT+ENTER (or \"Run cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset ####\n",
    "In this activity, we use the following example dataset D which is a simply array to demonstrate data partitioning and parallel searching. Run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our example dataset D consisting of 30 numeric elements.\n",
    "D = [55,30,68,39,1,\n",
    "      4,49,90,34,76,\n",
    "      82,56,31,25,78,\n",
    "      56,38,32,88,9,\n",
    "      44,98,11,70,66,\n",
    "      89,99,22,23,26]\n",
    "\n",
    "print(D) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Partitioning ##\n",
    "\n",
    "Data partitioning is the fundamental step for parallel search algorithms as parallelism in query and search processing is achieved through data partionining. \n",
    "In this activity, we will consider the following **four** partitioning strategies:\n",
    " * **Round-robin data partitioning**,\n",
    " * **Hash data partitioning**,\n",
    " * **Range data partitioning**, and\n",
    " * **Random-unequal data partitioning**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Round-robin data partitioning ###\n",
    "Round-robin data partitioning is the simplest data partitioning method in which each record in turn is allocated to a processing element (simply processor). Since it distributes the data evenly among all processors, it is also known as \"equal-partitioning\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Understand the following code of round-robin data partitioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round-robin data partitionining function\n",
    "def rr_partition(data, n):\n",
    "    \"\"\"\n",
    "    Perform data partitioning on data\n",
    "\n",
    "    Arguments:\n",
    "    data -- an input dataset which is a list\n",
    "    n -- the number of processors\n",
    "\n",
    "    Return:\n",
    "    result -- the paritioned subsets of D\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        result.append([])\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    \n",
    "    # For each bin, perform the following\n",
    "    for index, element in enumerate(data): \n",
    "        # Calculate the index of the bin that the current data point will be assigned\n",
    "        index_bin = (int) (index % n)\n",
    "        #print(str(index) + \":\" + str(element))\n",
    "        result[index_bin].append(element)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the partitioned result\n",
    "rr_partition(D, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Hash data partitioning ###\n",
    "Hash data partitioning makes a partition based on a particular attribute using a hash function. The result of a hash function determines the processor where the record will be placed. Thus, all records within a partition have the same hash value.\n",
    "\n",
    "**Exercise**: Understand the following code of hash data partitioning. First, we define a very simple hash function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple hash function.\n",
    "def s_hash(x, n):\n",
    "    \"\"\"\n",
    "    Define a simple hash function for demonstration\n",
    "\n",
    "    Arguments:\n",
    "    x -- an input record\n",
    "    n -- the number of processors\n",
    "\n",
    "    Return:\n",
    "    result -- the hash value of x\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    result = x%n \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a hash value\n",
    "s_hash(11, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hash data partitionining function. \n",
    "# We will use the \"s_hash\" function defined above to realise this partitioning\n",
    "def h_partition(data, n):\n",
    "    \"\"\"\n",
    "    Perform hash data partitioning on data\n",
    "\n",
    "    Arguments:\n",
    "    data -- an input dataset which is a list\n",
    "    n -- the number of processors\n",
    "\n",
    "    Return:\n",
    "    result -- the paritioned subsets of D\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    dic = {} # We will use a dictionary\n",
    "    for x in data: # For each data record, perform the following\n",
    "        h = s_hash(x, n) # Get the hash key of the input\n",
    "        if (h in dic.keys()): # If the key exists\n",
    "            s = dic[h]\n",
    "            s.add(x)\n",
    "            dic[h] = s # Add the new input to the value set of the key\n",
    "        else: # If the key does not exist\n",
    "            s = set() # Create an empty value set\n",
    "            s.update({x})\n",
    "            dic[h] = s # Add the value set to the key\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the partitioned result\n",
    "h_partition(D, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Range data partitioning ###\n",
    "Range data partitioning records based on a given range of the partitioning attribute. For example,the student table is partitioned based on \"Last Name\" based on the alphabetical order (i.e. A ~ Z). \n",
    "\n",
    "**Exercise**: Understand the following code of range data partitioning. As our dataset D is represented by numerical values, we partition D according to numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range data partitionining function\n",
    "def range_partition(data, range_indices):\n",
    "    \"\"\"\n",
    "    Perform range data partitioning on data\n",
    "\n",
    "    Arguments:\n",
    "    data -- an input dataset which is a list\n",
    "    range_indices -- the index list of ranges to be split\n",
    "\n",
    "    Return:\n",
    "    result -- the paritioned subsets of D\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    ### START CODE HERE ###  \n",
    "    # First, we sort the dataset according their values  \n",
    "    new_data = list(data)\n",
    "    new_data.sort()\n",
    "\n",
    "    # Calculate the number of bins\n",
    "    n_bin = len(range_indices) \n",
    "\n",
    "    # For each bin, perform the following\n",
    "    for i in range(n_bin): \n",
    "        # Find elements to be belonging to each range\n",
    "        s = [x for x in new_data if x < range_indices[i]] \n",
    "        # Add the partitioned list to the result\n",
    "        result.append(s) \n",
    "        # Find the last element in the previous partition\n",
    "        last_element = s[len(s)-1]\n",
    "        # Find the index of of the last element\n",
    "        last = new_data.index(last_element)\n",
    "        # Remove the partitioned list from the dataset\n",
    "        new_data = new_data[int(last)+1:] \n",
    "\n",
    "        # Append the last remaining data list\n",
    "    result.append([x for x in new_data if x >= range_indices[n_bin-1]]) \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the partitioned result\n",
    "range_partition(D, [40, 80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Random-unequal data partitioning ###\n",
    "In random-unequal data partitioning, the size of each partition is likely to be unequal. The word “random” in the\n",
    "name indicates that the records within each partition are not grouped semantically, but are randomly allocated.\n",
    "\n",
    "**Exercise**: Implement random-unequal data partitioning based on your definition. Referring to the function, **rr_partition()**, **complete the following code block between \"### START CODE HERE ###\" and \"### END CODE HERE ###\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Random-unequal data partitionining function\n",
    "def re_partition(data, n):\n",
    "    \"\"\"\n",
    "    Perform random-unequal data partitioning on data\n",
    "\n",
    "    Arguments:\n",
    "    data -- an input dataset which is a list\n",
    "    n -- the number of processors\n",
    "\n",
    "    Return:\n",
    "    result -- the paritioned subsets of D\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    random.shuffle(data)\n",
    "    em_length = len(data) // n # floor division (return int)\n",
    "    em_extra = len(data) % n\n",
    "    start = 0\n",
    "    for i in range(n):\n",
    "        if i < em_extra:\n",
    "            end = start + em_length + 1\n",
    "        else:\n",
    "            end = start + em_length\n",
    "        result.append(data[start:end])\n",
    "        start = end\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the partitioned result. \n",
    "# Compare the result with the one obtained from rr_partition(.).\n",
    "re_partition(D, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Generate the partitioned outputs in the form of the \"hash data partitioning\". That is, each partition can be represented as \"partition id: [list of elements]\". The \"partition id\" is any unique number or label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2: Search Algorithms ##\n",
    "\n",
    "Before discussing parallel search, it is important to know how searching is done serially. Making use of serial search algorithms with data partitioning will become the basis for parallel search algorithms.\n",
    "In this activity, we will consider the following **two** serial search algorithms:\n",
    " * **Linear Search**\n",
    " * **Binary Search**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Linear Search ###\n",
    "Linear search is the simplest approach to searching. Given an unsorted table of records, it scans the entire table to search for a given record. As this is performed for each record one by one until either the desired record is found or the end of table is reached, this algorithms is also known as an “exhaustive search.”\n",
    "\n",
    "**Exercise**: We use the dataset D to understand how this algorithm works. Each element in D will be considered as a data record. Let's understand how linear search works on D, and analyse its performance by the \"O\" notation which is normally used to measure the complexity of an algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear search function\n",
    "def linear_search(data, key):\n",
    "    \"\"\"\n",
    "    Perform linear search on data for the given key\n",
    "\n",
    "    Arguments:\n",
    "    data -- an input dataset which is a list or a numpy array\n",
    "    key -- an query record\n",
    "\n",
    "    Return:\n",
    "    result -- the position of searched record\n",
    "    \"\"\"\n",
    "    \n",
    "    matched_record = None\n",
    "    position = -1 # not found position\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    for x in data:\n",
    "        if x == key: # If x is matched with key\n",
    "            matched_record = x\n",
    "            position = data.index(x) # Get the index of x\n",
    "            break\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return position, matched_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_search (D, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Binary Search ###\n",
    "Binary search requires that the list be already completely in order. It starts by comparing the key with the middle entry of an ordered table. If it finds the matched record, it returns its index, otherwise, this process continues using either the lower or upper half of the table (depending on the value of the key). \n",
    "\n",
    "**Exercise**: **Build a binary search function by completing the code block below between \"### START CODE HERE ###\" and \"### END CODE HERE ###\"**. Discuss its complexity by comparing with the linear search algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary search function\n",
    "def binary_search(data, key):\n",
    "    \"\"\"\n",
    "    Perform binary search on data for the given key\n",
    "\n",
    "    Arguments:\n",
    "    data -- an input dataset which is a list\n",
    "    key -- an query record\n",
    "\n",
    "    Return:\n",
    "    result -- the position of searched record\n",
    "    \"\"\"\n",
    "    \n",
    "    matched_record = None\n",
    "    position = -1 # not found position\n",
    "    \n",
    "    lower = 0\n",
    "    middle = 0\n",
    "    upper = len(data)-1\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    while (lower <= upper):\n",
    "        # calculate middle: the half of lower and upper\n",
    "        middle = int((lower + upper)/2) \n",
    "        \n",
    "        if (key == data[middle]):\n",
    "            # if we find the matched one\n",
    "            position = middle\n",
    "            matched_record = data[middle]\n",
    "            break\n",
    "        elif (key > data[middle]):\n",
    "            # reduce to the top half of the list\n",
    "            lower = middle + 1\n",
    "        else:\n",
    "            # reduce to the bottom half of the list\n",
    "            upper = middle - 1\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return position, matched_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortD = list(D) # Copy the dataset\n",
    "sortD.sort() # Sort the dataset first\n",
    "binary_search (sortD, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table style = \"width:40%\">\n",
    "    <tr>\n",
    "    <td>** binary_search (sortD, 31) **</td> \n",
    "        <td>(9, 31)</td> \n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Perform the binary search function above with the unsorted data D. What will happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Parallel Search Algorithms ##\n",
    "\n",
    "Parallel search algorithms have three main elements: \n",
    "* **processor activation or involvement**\n",
    "* **local searching method**\n",
    "* **key comparison**\n",
    "\n",
    "Processor activation or involvement indicates the number of processors to be used by the algorithm. \n",
    "\n",
    "Local searching method is the searching method to be applied to the processor(s). The search method is dependent upon the data ordering. If the data has already been sorted, then a binary search can be used, and otherwise, a linear search can be conducted. \n",
    "\n",
    "Searching basically consists of comparing the data from the table with the condition specified by the user. When a match is found, there are two options: whether to continue the comparison process in order to find more matches, or whether to stop the entire process. It is obvious that the key comparison is dependent upon whether the search attribute values are, or are not, unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Parallel Searching for Exact Match ###\n",
    "In this activity, we will understand and practice how parallel searching works for **exact match search** for a given query. Note that the number of processors to perform parallel searching is dependent on the data partitioning methods. For example, only one processor is needed if the data is already partioned with a range partitioning. In this case, there is no parallelism.\n",
    "\n",
    "**Exercise**: We build a parallel search algorithm for exact match. Processor activation will be given by the user as input. As a location searching method, we will use the above two search functions: linear search function (i.e. linear_search()) and binary search function (i.e. binary_search()). As a local comparison method, we assume that we stop when a match is found for brevity. As data partitioning methods, we attempt to use the four different partitioning methods we built above:\n",
    " * Round-robin data partitioning (i.e. rr_partition()),\n",
    " * Hash data partitioning (i.e. h_partition()),\n",
    " * Range data partitioning (i.e. range_partition()), and\n",
    " * Random-unequal data partitioning (i.e. re_partition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp # For multiprocessing\n",
    "\n",
    "# Parallel searching algorithm for exact match\n",
    "def parallel_search_exact(data, query, n_processor, m_partition, m_search):\n",
    "    \"\"\"\n",
    "    Perform parallel search for exact match on data for the given key\n",
    "\n",
    "    Arguments:\n",
    "    data -- an input dataset which is a list\n",
    "    query -- a query record\n",
    "    n_processor -- the number of parallel processors\n",
    "    m_partition -- a data partitioning method\n",
    "    m_search -- a search method\n",
    "    \n",
    "    Return:\n",
    "    results -- the matched record information\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Pool: a Python method enabling parallel processing. \n",
    "    # We need to set the number of processes to n_processor, \n",
    "    # which means that the Pool class will only allow 'n_processor' processes \n",
    "    # running at the same time.\n",
    "    pool = mp.Pool(processes=n_processor)\n",
    "\n",
    "    ### START CODE HERE ###        \n",
    "\n",
    "    print(\"data partitioning:\" + str(m_partition.__name__))\n",
    "    print(\"searching method:\" + str(m_search.__name__))\n",
    "\n",
    "    if m_partition == range_partition: # for range partitioning method\n",
    "        # Perform data partitioning:\n",
    "        # 2nd parameter is a list of maximum range values (3 ranges)\n",
    "        range_indices = [40, 80]   # ideally pass this into the function as a variable\n",
    "        DD = m_partition(data, range_indices)\n",
    "        for index,element in enumerate(range_indices):\n",
    "            if query < element:\n",
    "                m = DD[index]\n",
    "                break\n",
    "            else:\n",
    "                m = DD[-1]\n",
    "        result = pool.apply(m_search, [m, query])\n",
    "        results.append(result)\n",
    "\n",
    "    elif m_partition == h_partition: # for hash partitioning method\n",
    "        # Perform data partitioning first\n",
    "        DD = m_partition(data, n_processor) \n",
    "        # Each element in DD has a pair (hash key: records)\n",
    "        query_hash = s_hash(query, n_processor)\n",
    "        d = list(DD[query_hash])\n",
    "        result = pool.apply(m_search, [d, query])\n",
    "        results.append(result)\n",
    "\n",
    "    else: # for round-robin or random-unequal partitioning method\n",
    "        # Perform data partitioning first\n",
    "        DD = m_partition(data, n_processor)      \n",
    "        for d in DD: # Perform parallel search on all data partitions    \n",
    "            print(d)\n",
    "            result = pool.apply_async(m_search, [d, query])\n",
    "            output = result.get() # if you use pool.apply_sync(), uncomment this.\n",
    "            results.append(output) # if you use pool.apply_sync(), uncomment this.\n",
    "            #results.append(result) # if you use pool.apply_sync(), comment out this.\n",
    "\n",
    "         \n",
    "    \"\"\" \n",
    "    The method 'pool.apply()' will lock the function call until the function call is finished. \n",
    "    The method 'pool.apply_sync()' will not lock the function call,the call results will return immediately instead \n",
    "    of waiting for the result, and each method call will be alloacted to a different process. \n",
    "    So in this case,pool.apply_async() is processing the search in parallel,\n",
    "    while the pool.apply() is not. \n",
    "    The reason we can use pool.apply() to do search for range_partition and hash_partition data \n",
    "    is that as long as we know which partition to do search，we don't need to search in parallel.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Test each of the following functions one by one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common input values\n",
    "data = D # input data\n",
    "sortD = list(data)\n",
    "sortD.sort()\n",
    "query = 31 # query term\n",
    "n_processor = 3 # number of parallel processors\n",
    "\n",
    "### parallel searching for exact match\n",
    "\n",
    "# round-robin partition, linear_search\n",
    "results = parallel_search_exact(data, query, n_processor, rr_partition, linear_search)\n",
    "print(results) \n",
    "\n",
    "# round-robin partition, binary_search\n",
    "results = parallel_search_exact(sortD, query, n_processor, rr_partition, binary_search)\n",
    "print(results)\n",
    "\n",
    "# random-unequal partition, linear_search\n",
    "results = parallel_search_exact(data, query, n_processor, re_partition, linear_search)\n",
    "print(results)\n",
    "\n",
    "# random-equal partition, binary_search\n",
    "results = parallel_search_exact(sortD, query, n_processor, re_partition, binary_search)\n",
    "print(results)\n",
    "\n",
    "# Hash partition, linear_search\n",
    "results = parallel_search_exact(data, query, n_processor, h_partition, linear_search)\n",
    "print(results)\n",
    "\n",
    "# Hash partition, binary_search\n",
    "results = parallel_search_exact(sortD, query, n_processor, h_partition, binary_search)\n",
    "print(results)\n",
    "\n",
    "# The above function can't find the query term. Can you identify why?\n",
    "# Range partition, linear_search\n",
    "results = parallel_search_exact(data, query, n_processor, range_partition, linear_search)\n",
    "print(results)\n",
    "\n",
    "# Range partition, binary_search\n",
    "results = parallel_search_exact(sortD, query, n_processor, range_partition, binary_search)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: What do we see from the results? We see the set of the pairs each consistings of the position and value of the matched recored given a query. The -1 position indicates the query was not found. If found, a position is > -1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Parallel Searching for Range Selection (Continuous) ###\n",
    "In this activity, we will build a parallel search algorithm for **range selection (continuous)** for a given query. In this practice, we attempt to implement one particular search algorithm which is instructed below.\n",
    "\n",
    "**Exercise**: **Build a parallel search algorithm** that uses the linear search algorithm (i.e. linear_search()) and is able to work with the hash partitioning method (i.e. h_partition()). **Complete the code block between \"### START CODE HERE ###\" and \"### END CODE HERE ###\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "# Parallel searching algorithm for range selection\n",
    "def parallel_search_range(data, query_range, n_processor):\n",
    "    \"\"\"\n",
    "    Perform parallel search for range selection on data for the given key\n",
    "\n",
    "    Arguments:\n",
    "    data -- the input dataset which is a list\n",
    "    query_range -- a query record in the form of a range (e.g. [30, 50])\n",
    "    n_processor -- the number of parallel processors\n",
    "    \n",
    "    Return:\n",
    "    results -- the matched record information\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    pool = Pool(processes=n_processor)\n",
    "\n",
    "    ### START CODE HERE ###        \n",
    "    \n",
    "    # Perform data partitioning first\n",
    "    DD = h_partition(data, n_processor) \n",
    "    \n",
    "    for query in range(query_range[0], query_range[1], 1):\n",
    "        # Each element in DD has a pair (hash key: records)\n",
    "        query_hash = s_hash(query, n_processor)\n",
    "        d = list(DD[query_hash])\n",
    "        result = pool.apply(linear_search, [d, query])\n",
    "        results.append(result)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range partition, linear_search \n",
    "results = parallel_search_range(data, [30, 40], n_processor)\n",
    "print(results) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "<table style = \"width:80%\">\n",
    "    <tr>\n",
    "    <td>** parallel_search_range(data, [30, 40], n_processor) **</td> \n",
    "        <td>[(6, 30), (11, 31), (0, 32), (1, 34), (3, 38), (2, 39)]</td> \n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you interprete the output?\n",
    "\n",
    "Congratulations on finishing this activity!\n",
    "\n",
    "<font color='blue'>\n",
    "**Wrap up what we've learned:**\n",
    "- We are now able to build different data partitioning strategies\n",
    "- We are familiar with basic search algorithms - linear search and binary search algorithms\n",
    "- More importantly, we can now build parallel search algorithms based on various data partitioning strategies and basic search algorithms\n",
    "- We understand how parallel search algorithms can be working for exact query match or range selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
